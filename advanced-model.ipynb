{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-b6383702",
   "language": "python",
   "display_name": "PyCharm (house-prices-advanced-regression-techniques)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, \\\n",
    "    RobustScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "set_config(display='diagram')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = trainDf = pd.read_csv(\"data/train.csv\")\n",
    "test_df = testDf = pd.read_csv(\"data/test.csv\")\n",
    "full_df = fullDf = pd.concat([trainDf, testDf], sort=True).reset_index(drop=True)"
   ]
  },
  {
   "source": [
    "## Misc Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X_train, y_train, cv, train_sizes=np.linspace(0.1, 1, 10)):\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X_train, y_train, \n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        train_sizes=train_sizes,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "        )\n",
    "    train_mean_scores = np.mean(train_scores, axis=1)\n",
    "    test_mean_scores = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.title('Learning curve')\n",
    "    plt.plot(train_sizes, train_mean_scores, 'y', label='Train Learning curve')\n",
    "    plt.plot(train_sizes, test_mean_scores, 'b', label='Test Learning curve')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_rmsle(y_true, y_pred):\n",
    "    return -1 * np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, X, Y):\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        model, X, Y, \n",
    "        scoring=['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error'], cv=2,\n",
    "        n_jobs=-1, verbose=0)\n",
    "\n",
    "    rmsle_score = cross_val_score(model, X, Y, cv=2, scoring=make_scorer(neg_rmsle))\n",
    "\n",
    "    mse_score = -1 * scores['test_neg_mean_squared_error'].mean()\n",
    "    mse_std = scores['test_neg_mean_squared_error'].std()\n",
    "\n",
    "    mae_score = -1 * scores['test_neg_mean_absolute_error'].mean()\n",
    "    mae_std = scores['test_neg_mean_absolute_error'].std()\n",
    "\n",
    "    r2_score_mean = scores['test_r2'].mean()\n",
    "    r2_std = scores['test_r2'].std()\n",
    "\n",
    "    print('[CV] MSE: %.4f (%.4f)' % (mse_score, mse_std))\n",
    "    print('[CV] MAE: %.4f (%.4f)' % (mae_score, mae_std))\n",
    "    print('[CV] R^2: %.4f (%.4f)' % (r2_score_mean, r2_std))\n",
    "    print('[CV] RMSLE: %.6f (%.4f)' % (rmsle_score.mean(), rmsle_score.std()))"
   ]
  },
  {
   "source": [
    "## Data Cleaning and Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [f for f in full_df.columns if full_df.dtypes[f] != 'object']\n",
    "num_features.remove('Id')\n",
    "num_features.remove('SalePrice')\n",
    "\n",
    "cat_features = [f for f in full_df.columns if full_df.dtypes[f] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in (\n",
    "    'PoolQC', \n",
    "    'FireplaceQu', \n",
    "    'Alley', \n",
    "    'Fence', \n",
    "    'MiscFeature', \n",
    "    'BsmtQual', \n",
    "    'BsmtCond', \n",
    "    'BsmtExposure', \n",
    "    'BsmtFinType1', \n",
    "    'BsmtFinType2',\n",
    "    'GarageType', \n",
    "    'GarageFinish', \n",
    "    'GarageQual', \n",
    "    'GarageCond',\n",
    "    'BsmtQual', \n",
    "    'BsmtCond', \n",
    "    'BsmtExposure', \n",
    "    'BsmtFinType1', \n",
    "    'BsmtFinType2',\n",
    "    'MasVnrType',\n",
    "    'MSSubClass',\n",
    "):\n",
    "    train_df[feature] = train_df[feature].fillna('None')\n",
    "    test_df[feature] = test_df[feature].fillna('None')\n",
    "    full_df[feature] = full_df[feature].fillna('None')\n",
    "\n",
    "for feature in (\n",
    "    'BsmtFinSF1', \n",
    "    'BsmtFinSF2', \n",
    "    'BsmtUnfSF',\n",
    "    'TotalBsmtSF', \n",
    "    'BsmtFullBath', \n",
    "    'BsmtHalfBath',\n",
    "    'MasVnrArea',\n",
    "    'GarageCars',\n",
    "    'GarageArea',\n",
    "    'GarageYrBlt',\n",
    "):\n",
    "    train_df[feature] = train_df[feature].fillna(0)\n",
    "    test_df[feature] = test_df[feature].fillna(0)\n",
    "    full_df[feature] = full_df[feature].fillna(0)\n",
    "\n",
    "for feature in (\n",
    "    'Electrical', \n",
    "    'KitchenQual', \n",
    "    'Exterior1st',\n",
    "    'Exterior2nd', \n",
    "    'SaleType',\n",
    "    'MSZoning',\n",
    "    'Utilities',\n",
    "):\n",
    "    train_df[feature] = train_df[feature].fillna(train_df[feature].mode()[0])\n",
    "    test_df[feature] = test_df[feature].fillna(test_df[feature].mode()[0])\n",
    "    full_df[feature] = full_df[feature].fillna(test_df[feature].mode()[0])\n",
    "\n",
    "train_df['Functional'] = train_df['Functional'].fillna('Typical')\n",
    "test_df['Functional'] = test_df['Functional'].fillna('Typical')\n",
    "full_df['Functional'] = full_df['Functional'].fillna('Typical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in [train_df, test_df]:\n",
    "    dataframe['Exterior1st'].replace(['Brk Cmn', 'CmentBd', 'Wd Shng'], ['BrkComm', 'CemntBd', 'Wd Sdng'], inplace=True)\n",
    "    dataframe['Exterior2nd'].replace(['Brk Cmn', 'CmentBd', 'Wd Shng'], ['BrkComm', 'CemntBd', 'Wd Sdng'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_feature_mapping = {\n",
    "    'ExterQual': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}, \n",
    "    'ExterCond': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'HeatingQC': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'KitchenQual': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'FireplaceQu': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},\n",
    "    'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'PoolQC': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'Fence': {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4},\n",
    "    'PavedDrive': {'N': 0, 'P': 1, 'Y': 2},\n",
    "    'CentralAir': {'N': 0, 'Y': 1},\n",
    "    'Alley': {'None': 0, 'Pave': 1, 'Grvl': 2},\n",
    "    'Street': {'Pave': 0, 'Grvl': 1},\n",
    "    'Functional': {'Sal': 0, 'Sev': 1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7}\n",
    "}\n",
    "\n",
    "non_ordinal_cat_features = list(set(cat_features) - set(ordinal_feature_mapping.keys()))\n",
    "\n",
    "for cat_feature in non_ordinal_cat_features:\n",
    "    train_df[cat_feature + 'Enc'] = LabelEncoder().fit_transform(train_df[cat_feature])\n",
    "    test_df[cat_feature + 'Enc'] = LabelEncoder().fit_transform(test_df[cat_feature])\n",
    "\n",
    "for ordinal_feature, feature_mapping in ordinal_feature_mapping.items():\n",
    "    train_df[ordinal_feature + 'Enc'] = train_df[ordinal_feature].map(feature_mapping)\n",
    "    test_df[ordinal_feature + 'Enc'] = test_df[ordinal_feature].map(feature_mapping)"
   ]
  },
  {
   "source": [
    "### Num Feature Scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "source": [
    "## Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in [train_df, test_df]:\n",
    "    dataframe['Has2ndFloor'] = dataframe['2ndFlrSF'].apply(lambda x: int(x > 0))\n",
    "    dataframe['HasBsmnt'] = dataframe['TotalBsmtSF'].apply(lambda x: int(x > 0))\n",
    "    dataframe['HasGarage'] = dataframe['GarageArea'].apply(lambda x: int(x > 0))\n",
    "    dataframe['HasPool'] = dataframe['PoolArea'].apply(lambda x: int(x > 0))\n",
    "    dataframe['HasFence'] = dataframe['Fence'].apply(lambda x: int(x != 'None'))\n",
    "    dataframe['HasFireplace'] = dataframe['Fireplaces'].apply(lambda x: int(x > 0))\n",
    "    dataframe['HasMasVnr'] = dataframe['MasVnrType'].apply(lambda x: int(x != 'None'))\n",
    "\n",
    "    dataframe['HouseAge'] = dataframe['YrSold'].astype('int') - dataframe['YearBuilt'].astype('int')\n",
    "    dataframe['HouseAgeSinRemod'] = dataframe['YrSold'].astype('int') - dataframe['YearRemodAdd'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train_df.drop(\n",
    "    train_df[(train_df['GrLivArea'] > 4000) & (train_df['SalePrice'] < 700000)].index\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclassCategories = [20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 150, 160, 180, 190]\n",
    "basementFinishCategories = ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']\n",
    "electricalCategories = ['Mix', 'FuseP', 'FuseF', 'FuseA', 'SBrkr']\n",
    "\n",
    "exteriorCategories = ['AsbShng', 'AsphShn', 'BrkComm', 'BrkFace', 'CBlock', 'CemntBd', 'HdBoard', 'ImStucc', 'MetalSd', 'Other', 'Plywood', 'PreCast', 'Stone', 'Stucco', 'VinylSd', 'Wd Sdng', 'WdShing']\n",
    "\n",
    "conditionCategories = train_df['Condition1'].unique()\n",
    "neighborhoodCategories = full_df['Neighborhood'].unique()\n",
    "saleCondCategories = full_df['SaleCondition'].unique()\n",
    "garageTypeCategories = full_df['GarageType'].unique()\n",
    "lotConfigCategories = full_df['LotConfig'].unique() # feature was removed from the model\n",
    "lotShapeCategories = full_df['LotShape'].unique()\n",
    "landSlopeCategories = full_df['LandSlope'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1871.        , 1886.44444444, 1901.88888889, 1917.33333333,\n",
       "       1932.77777778, 1948.22222222, 1963.66666667, 1979.11111111,\n",
       "       1994.55555556, 2010.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "year_built_bins = np.linspace(1871, 2010, 10) # 10 bins\n",
    "\n",
    "year_built_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/cerberus4229/voting-regressor-with-pipelines\n",
    "\n",
    "for dataframe in [train_df, test_df]:\n",
    "    dataframe['TotalBathrooms'] = (dataframe['FullBath'] + (0.5 * dataframe['HalfBath']) +\n",
    "                                dataframe['BsmtFullBath'] + (0.5 * dataframe['BsmtHalfBath']))\n",
    "\n",
    "    dataframe['OverallHouseQCBin'] = pd.qcut(dataframe['OverallQual'] + dataframe['OverallCond'], q=3, labels=[0, 1, 2]) # performs worse than OverallQual\n",
    "    dataframe['IsPavedDrive'] = (dataframe['PavedDrive'] == 'Y') * 1 # performs worse\n",
    "    dataframe['IsNeighborhoodElite'] = (dataframe['Neighborhood'].isin(['NridgHt', 'CollgeCr', 'Crawfor', 'StoreBr', 'Timber'])) * 1 # worse\n",
    "    dataframe['YearBuiltBin'] = pd.cut(dataframe['YearBuilt'], bins=year_built_bins, labels=range(1, 10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/humananalog/xgboost-lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = [\n",
    "    '1stFlrSF',\n",
    "    '2ndFlrSF',\n",
    "    'BsmtFinSF1', \n",
    "    'BsmtFinSF2',\n",
    "    'BsmtUnfSF', #\n",
    "    'BsmtFinType1Enc',\n",
    "    'BsmtFinType2Enc',\n",
    "    'OverallQual',\n",
    "    'GarageCars',\n",
    "    'OverallCond', \n",
    "    'Neighborhood',\n",
    "    'MSSubClass', \n",
    "    'LotShape',\n",
    "    'LandSlope',\n",
    "    'BsmtCondEnc',\n",
    "    'BsmtQualEnc', #\n",
    "    'SaleCondition',\n",
    "    'CentralAirEnc',\n",
    "    'Condition1',\n",
    "    'Condition2',\n",
    "    'TotalBathrooms',\n",
    "    'GarageFinishEnc',\n",
    "    'KitchenQualEnc',\n",
    "    'BedroomAbvGr',\n",
    "    #'IsNeighborhoodElite',\n",
    "    #'YearBuiltBin',    \n",
    "]\n",
    "\n",
    "X = train_df[baseline_features]\n",
    "Y = train_df['SalePrice']"
   ]
  },
  {
   "source": [
    "## Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature transformer\n",
    "\n",
    "logTransformer = FunctionTransformer(func=np.log1p, inverse_func=np.expm1)\n",
    "\n",
    "featureTransformer = ColumnTransformer([\n",
    "        ('basement_area_log', logTransformer, ['BsmtFinSF1', 'BsmtFinSF2']),\n",
    "        ('neighborhood_onehot', OneHotEncoder(categories=[neighborhoodCategories]), ['Neighborhood']),\n",
    "        ('subclass_onehot', OneHotEncoder(categories=[subclassCategories]), ['MSSubClass']),\n",
    "        ('lot_shape_onehot', OneHotEncoder(categories=[lotShapeCategories]), ['LotShape']),\n",
    "        ('land_slope_onehot', OneHotEncoder(categories=[landSlopeCategories]), ['LandSlope']),\n",
    "        ('sale_condtion_onehot', OneHotEncoder(categories=[saleCondCategories]), ['SaleCondition']),\n",
    "        ('condition_onehot', OneHotEncoder(categories=[conditionCategories, conditionCategories]), ['Condition1', 'Condition2']), #\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "source": [
    "### ElasticNet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SVR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/marktsvirko/votingregressor-xgb-svm-top-10"
   ]
  },
  {
   "source": [
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] MSE: 889831012.8445 (46061331.0130)\n[CV] MAE: 17721.0043 (817.3113)\n[CV] R^2: 0.8587 (0.0015)\n[CV] RMSLE: -0.147753 (0.0071)\n"
     ]
    }
   ],
   "source": [
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessing', featureTransformer),\n",
    "    ('random_forest', RandomForestRegressor(\n",
    "        bootstrap=True,\n",
    "        max_depth=25,\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=1000,\n",
    "        random_state=42,\n",
    "    )),\n",
    "])\n",
    "\n",
    "# Measure performance\n",
    "\n",
    "score_model(random_forest_pipeline, X, Y)\n",
    "\n",
    "## RF(max_depth=15, max_features='sqrt', min_samples_leaf=1, min_samples_split=3, n_estimators=3650)\n",
    "## CV=2, ?\n",
    "#[CV] MSE: 904073278.0912 (34098840.2146)\n",
    "#[CV] MAE: 17896.4251 (795.0885)\n",
    "#[CV] R^2: 0.8563 (0.0036)\n",
    "\n",
    "## RF(max_depth=25, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, n_estimators=1000)\n",
    "## CV=2, 0.15007\n",
    "#[CV] MSE: 889831012.8445 (46061331.0130)\n",
    "#[CV] MAE: 17721.0043 (817.3113)\n",
    "#[CV] R^2: 0.8587 (0.0015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.05519694734604319, '1stFlrSF'),\n",
       " (0.02045785438167182, 'LotShape'),\n",
       " (0.014138410467452114, 'BsmtFinType1Enc'),\n",
       " (0.0044588645275103235, 'TotalBathrooms'),\n",
       " (0.0037306632246330842, '2ndFlrSF'),\n",
       " (0.0034934266166744892, 'BsmtUnfSF'),\n",
       " (0.003006848415812425, 'CentralAirEnc'),\n",
       " (0.002968784317162521, 'LandSlope'),\n",
       " (0.0028891298209607653, 'OverallQual'),\n",
       " (0.0026660984904356413, 'OverallCond'),\n",
       " (0.0019403479623190366, 'BsmtFinSF1'),\n",
       " (0.001765659505820689, 'GarageFinishEnc'),\n",
       " (0.0016733526160927765, 'Condition1'),\n",
       " (0.0012974703679510767, 'Condition2'),\n",
       " (0.0012167302515332097, 'GarageCars'),\n",
       " (0.0011803714262773907, 'BsmtQualEnc'),\n",
       " (0.0010871917076662066, 'MSSubClass'),\n",
       " (0.0009796199960676042, 'BsmtCondEnc'),\n",
       " (0.0009447523171870062, 'BsmtFinType2Enc'),\n",
       " (0.0008163424115430446, 'SaleCondition'),\n",
       " (0.000740781374314616, 'Neighborhood'),\n",
       " (0.0006476959841260213, 'BedroomAbvGr'),\n",
       " (0.0005070349684867455, 'BsmtFinSF2'),\n",
       " (0.00011473826000025075, 'KitchenQualEnc')]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "random_forest_pipeline.fit(X, Y)\n",
    "random_forest_pipeline.named_steps['random_forest'].feature_importances_\n",
    "\n",
    "features_list = sorted(zip(random_forest_pipeline.named_steps['random_forest'].feature_importances_, X.columns), reverse=True)\n",
    "\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "\n",
    "parameters = {\n",
    "    'random_forest__bootstrap': [True],\n",
    "    'random_forest__max_depth': [8, 10, 15, 20, 25, 30],\n",
    "    'random_forest__max_features': ['sqrt'],\n",
    "    'random_forest__min_samples_leaf': [1, 2, 5],\n",
    "    'random_forest__min_samples_split': [1, 2, 5],\n",
    "    'random_forest__n_estimators': [800, 1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "#paramSearch = GridSearchCV(\n",
    "#  estimator=random_forest_pipeline,\n",
    "#  scoring=make_scorer(neg_rmsle),\n",
    "#  param_grid=parameters, \n",
    "#  cv=2,\n",
    "#  n_jobs=-1, \n",
    "#  verbose=2\n",
    "#)\n",
    "\n",
    "#paramSearch.fit(X, Y)\n",
    "#paramSearch.best_params_, paramSearch.best_score_\n",
    "\n",
    "#{'random_forest__bootstrap': True,\n",
    "# 'random_forest__max_depth': 25,\n",
    "# 'random_forest__max_features': 'sqrt',\n",
    "# 'random_forest__min_samples_leaf': 1,\n",
    "# 'random_forest__min_samples_split': 2,\n",
    "# 'random_forest__n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_learning_curve(random_forest_pipeline, X, Y, cv=3)"
   ]
  },
  {
   "source": [
    "### XGBoostRegressor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] MSE: 783066174.7649 (1966607.6233)\n[CV] MAE: 16238.1809 (437.5458)\n[CV] R^2: 0.8752 (0.0081)\n[CV] RMSLE: -0.130143 (0.0044)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessing', featureTransformer),\n",
    "    ('xgb_regressor', XGBRegressor(\n",
    "        max_depth=5,\n",
    "        n_estimators=7050,\n",
    "        learning_rate=0.01,\n",
    "        min_child_weight=1.5,\n",
    "        subsample=0.2,\n",
    "        gamma=0,\n",
    "        reg_alpha=1,\n",
    "        reg_lambda=0.1,\n",
    "        objective='reg:gamma',\n",
    "        booster='gbtree'\n",
    "    )),\n",
    "])\n",
    "\n",
    "# Measure Performance\n",
    "\n",
    "score_model(xgb_pipeline, X, Y)\n",
    "\n",
    "## XGB (max_depth=8, n_estimators=200, learning_rate=0.06, min_child_weight=3, booster='gbtree', subsample=0.7, gamma=0)\n",
    "## CV=2, 0.13494\n",
    "# [CV] MSE: 782138754.8110 (37985553.8400)\n",
    "# [CV] MAE: 16999.5631 (458.6830)\n",
    "# [CV] R^2: 0.8758 (0.0017)\n",
    "# [CV] RMSLE: -0.133976\n",
    "\n",
    "# XGB (max_depth=4, n_estimators=7000, learning_rate=0.01, min_child_weight=1.5, subsample=0.2, gamma=0, reg_alpha=1, reg_lambda=0.1, booster='gbtree')\n",
    "## CV=2, 0.13105\n",
    "# [CV] MSE: 782885721.1446 (6743520.5426)\n",
    "# [CV] MAE: 16302.8672 (471.5882)\n",
    "# [CV] R^2: 0.8754 (0.0067)\n",
    "# [CV] RMSLE: -0.130275 (0.0048)\n",
    "\n",
    "# XGB (max_depth=5, n_estimators=7000, learning_rate=0.01, min_child_weight=1.5, subsample=0.2, gamma=0, reg_alpha=1, reg_lambda=0.1, booster='gbtree')\n",
    "## CV=2, ?\n",
    "# [CV] MSE: 783160286.1791 (1231674.5549)\n",
    "# [CV] MAE: 16241.7409 (441.4740)\n",
    "# [CV] R^2: 0.8752 (0.0080)\n",
    "# [CV] RMSLE: -0.130159 (0.0045)\n",
    "\n",
    "##n_estimators=7050\n",
    "# CV=2, 0.13104\n",
    "#[CV] MSE: 783066174.7649 (1966607.6233)\n",
    "#[CV] MAE: 16238.1809 (437.5458)\n",
    "#[CV] R^2: 0.8752 (0.0081)\n",
    "#[CV] RMSLE: -0.130143 (0.0044)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.014051641, 'BsmtQualEnc'),\n",
       " (0.013857039, 'OverallCond'),\n",
       " (0.013152896, '1stFlrSF'),\n",
       " (0.01233868, 'SaleCondition'),\n",
       " (0.009447186, 'CentralAirEnc'),\n",
       " (0.009291395, 'BedroomAbvGr'),\n",
       " (0.0064481725, 'LandSlope'),\n",
       " (0.005881669, 'TotalBathrooms'),\n",
       " (0.0055863447, 'MSSubClass'),\n",
       " (0.005530742, 'BsmtUnfSF'),\n",
       " (0.0054482636, 'BsmtFinSF1'),\n",
       " (0.0052987006, 'GarageFinishEnc'),\n",
       " (0.00524099, 'GarageCars'),\n",
       " (0.004854181, 'OverallQual'),\n",
       " (0.004814755, 'BsmtCondEnc'),\n",
       " (0.0047640437, 'Neighborhood'),\n",
       " (0.004680495, 'BsmtFinType2Enc'),\n",
       " (0.0046787006, 'LotShape'),\n",
       " (0.004650164, 'Condition1'),\n",
       " (0.0043684505, '2ndFlrSF'),\n",
       " (0.0042710085, 'Condition2'),\n",
       " (0.0042392905, 'BsmtFinType1Enc'),\n",
       " (0.00390006, 'KitchenQualEnc'),\n",
       " (0.003170629, 'BsmtFinSF2')]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "xgb_pipeline.fit(X, Y)\n",
    "xgb_pipeline.named_steps['xgb_regressor'].feature_importances_\n",
    "\n",
    "features_list = sorted(zip(xgb_pipeline.named_steps['xgb_regressor'].feature_importances_, X.columns), reverse=True)\n",
    "\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'xgb_regressor__objective': ['reg:gamma'], # 'reg:squarederror', 'reg:squaredlogerror'\n",
    "    'xgb_regressor__learning_rate': [0.01],\n",
    "    'xgb_regressor__n_estimators': [6900, 7000, 7100],\n",
    "    'xgb_regressor__max_depth': [5],\n",
    "    'xgb_regressor__booster': ['gbtree'],\n",
    "    'xgb_regressor__min_child_weight': [1.5],\n",
    "    'xgb_regressor__gamma': [0],\n",
    "    'xgb_regressor__subsample': [0.2],\n",
    "    'xgb_regressor__reg_alpha': [1],\n",
    "    'xgb_regressor__reg_lambda': [0.1],\n",
    "}\n",
    "\n",
    "paramSearch = GridSearchCV(\n",
    "   estimator=xgb_pipeline,\n",
    "   scoring=make_scorer(neg_rmsle),\n",
    "   param_grid=parameters,\n",
    "   cv=2,\n",
    "   n_jobs=-1, \n",
    "   verbose=3\n",
    ")\n",
    "\n",
    "#paramSearch.fit(X, Y)\n",
    "#paramSearch.best_params_, paramSearch.best_score_\n",
    "\n",
    "#({'xgb_regressor__booster': 'gbtree',\n",
    "#  'xgb_regressor__gamma': 0.03,\n",
    "#  'xgb_regressor__learning_rate': 0.04,\n",
    "#  'xgb_regressor__max_depth': 5,\n",
    "#  'xgb_regressor__min_child_weight': 2,\n",
    "#  'xgb_regressor__n_estimators': 2000,\n",
    "#  'xgb_regressor__objective': 'reg:gamma',\n",
    "#  'xgb_regressor__subsample': 0.7},\n",
    "# -0.1293080016874709)\n",
    "\n",
    "#({'xgb_regressor__booster': 'gbtree',\n",
    "#  'xgb_regressor__gamma': 0.03,\n",
    "#  'xgb_regressor__learning_rate': 0.06,\n",
    "#  'xgb_regressor__max_depth': 5,\n",
    "#  'xgb_regressor__min_child_weight': 2,\n",
    "#  'xgb_regressor__n_estimators': 2000,\n",
    "#  'xgb_regressor__objective': 'reg:gamma',\n",
    "#  'xgb_regressor__subsample': 0.7},\n",
    "# -0.13023288188100762)\n",
    "\n",
    "#({'xgb_regressor__booster': 'gbtree',\n",
    "#  'xgb_regressor__gamma': 0.02,\n",
    "#  'xgb_regressor__learning_rate': 0.07,\n",
    "#  'xgb_regressor__max_depth': 2,\n",
    "#  'xgb_regressor__min_child_weight': 1,\n",
    "#  'xgb_regressor__n_estimators': 800,\n",
    "#  'xgb_regressor__objective': 'reg:gamma',\n",
    "#  'xgb_regressor__subsample': 0.8},\n",
    "# -0.12779856264607697)"
   ]
  },
  {
   "source": [
    "### StackRegressor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/lavanyashukla01/how-i-made-top-0-3-on-a-kaggle-competition"
   ]
  },
  {
   "source": [
    "### VotingRegressor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/marktsvirko/votingregressor-xgb-svm-top-10"
   ]
  },
  {
   "source": [
    "## Predict Submissions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_forest_pipeline.fit(X, Y)\n",
    "\n",
    "x_test = test_df[baseline_features]\n",
    "y_test_predicted = random_forest_pipeline.predict(x_test)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'SalePrice': y_test_predicted,\n",
    "})\n",
    "\n",
    "submission_df.to_csv('./data/submission_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline.fit(X, Y)\n",
    "\n",
    "x_test = test_df[baseline_features]\n",
    "y_test_predicted = xgb_pipeline.predict(x_test)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'SalePrice': y_test_predicted,\n",
    "})\n",
    "\n",
    "submission_df.to_csv('./data/submission_xgb.csv', index=False)"
   ]
  }
 ]
}